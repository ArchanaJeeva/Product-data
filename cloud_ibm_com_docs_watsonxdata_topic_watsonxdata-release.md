IBM Cloud Docs Skip to contentIBM CloudCatalogCatalogCost EstimatorCost EstimatorHelpHelpDocsLog inSign upError Skip to content IBM Cloud IBM Cloud CatalogCatalog CatalogCatalog Cost EstimatorCost Estimator Cost EstimatorCost Estimator HelpHelpDocs HelpHelp Docs Docs Docs Log in Log in Sign up Sign up Error Release notes for watsonx.data Release notes for watsonx.data Use these release notes to learn about the latest updates to IBMÂ® watsonx.data that are grouped by date. 31 May 2024 - Version 1.1.5 Provision Spark engine in watsonx.data Lite plan You can now add a small-sized Spark engine (single node) in the watsonx.data Lite plan instance. For more information, see watsonx.data Lite plan. Updates related to Spark labs Working with Jupyter Notebooks from Spark labs : You can now install the Jupyter extension from the VS Code Marketplace inside your Spark lab and work with Jupyter Notebooks. For more information, see Create Jupyter Notebooks. Accessing Spark UI from Spark labs You can now access the Spark user interface (UI) from Spark labs to monitor various aspects of running a Spark application. For more information, see Accessing Spark UI from Spark labs. New region to provision for IBM Cloud instance You can now provision your IBM Cloud instance in the Sydney region. 30 Apr 2024 - Version 1.1.4 A new version of watsonx.data was released in April 2024. This release includes the following features and updates: Kerberos authentication for HDFS connections You can now enable Kerberos authentication for secure Apache Hadoop Distributed File System (HDFS) connections. For more information, see HDFS. New data sources The following new data sources are now available: Oracle Amazon Redshift Informix Prometheus For more information, see Data sources. Test SSL connections You can now test SSL connections for the MongoDB and SingleStore data sources. Uploading description files for Apache Kafka data source The Apache Kafka data source stores data as byte messages that producers and consumers must interpret. To query this data, consumers must first map it into columns. Now, you can upload topic description files that convert raw data into a table format. Each file must be a JSON file that contains a definition for a table. To upload these JSON files from the UI, go to the overview page of the Apache Kafka database that you registered and select the Add topic option. For more information, see Apache Kafka. License plans for watsonx.data IBMÂ® watsonx.data now offers the following license plans. Lite plan BYOL plan Enterprise plan For more information about the different license plans, see IBMÂ® watsonx.data pricing plans. Presto engine version upgrade The Presto engine is now upgraded to version 0.285.1. Pause or resume Milvus You can now pause or resume Milvus service. Pausing your service can avoid incurring charges. Spark is now available as a native engine In addition to registering external Spark engines, you can now provision native Spark engine on your IBM watsonx.data instance. With native Spark engine, you can fully manage Spark Engine configuration, manage access to Spark Engines and view applications by using watsonx.data UI and REST API endpoints. For more information, see Provisioning Native Spark engine. Ingest data using native Spark Engines You can now submit ingestion jobs using native Spark Engines. For more information, see Working with Apache Hudi catalog and Working with Delta Lake catalog. 27 Mar 2024 - Version 1.1.3 A new version of watsonx.data was released in March 2024. This release includes the following features and updates: New data type for some data sources You can now use the BINARY data type with the SELECT statement in the Query workspace to build and run queries against your data for the following data sources: Elasticsearch SQL Server MySQL New data types: BLOB and CLOB are available for MySQL, PostgreSQL, Snowflake, SQL Server, and Db2 data sources. You can use these data types only with SELECT statements in the Query workspace to build and run queries against your data. Delete data by using the DELETE FROM feature for Iceberg data sources You can now delete data from tables in Iceberg data sources by using the DELETE FROM feature. You can specify the table property delete mode for new tables by using either copy-on-write mode or merge-on-read mode (default). For more information, see SQL statements. ALTER VIEW statement for Iceberg data source You can now use the following SQL statement in the Query workspace to build and run queries against your data for ALTER VIEW: ALTER VIEW name RENAME TO new\_name Upload SSL certificates for Netezza Performance Server data sources You can now browse and upload the SSL certificate for SSL connections in Netezza Performance Server data sources. The valid file formats for SSL certificate are .pem, .crt, and .cer. You can upload SSL certificates by using the Adding a database-catalog pair option in the Infrastructure manager. Query data from Db2 and Watson Query You can now query nicknames that are created in Db2 and virtualized tables from Watson Query instances. SSL connection for IBM Data Virtualization Manager for z/OS data source You can now enable SSL connection for the IBM Data Virtualization Manager for z/OS data source by using the Add database user interface to secure and encrypt the database connection. Select Validate certificate to validate whether the SSL certificate that is returned by the host is trusted. You can choose to provide the hostname in the SSL certificate. Use data from Apache Hudi catalog You can now connect to and use data from Apache Hudi catalog. Add Milvus as a service in watsonx.data You can now provision Milvus as a service inÂ watsonx.data with the following features: Provision different storage variants such as starter, medium, and large nodes. Assign Admin or User roles for Milvus users: User access policy is now available for Milvus users. Using the Access Control UI, you can assign Admin or User roles for Milvus users

andÂ also grant,Â revoke, or updateÂ the privilege. Configure the Object storage for Milvus to store data. You can add or configure a custom bucket and specify the username, password, region, and bucket URL. For more information, see Milvus. Load data in batch by using the ibm-lh ingestion tool You can now use the ibm-lh ingestion tool to run batch ingestion procedures in non-interactive mode (from outside the ibm-lh-tools container), by using the ibm-lh-client package. For more information, see ibm-lh commands and usage. Creating schema by using bulk ingestion in web console You can now create a schema by using the bulk ingestion process in the web console, if the schema is not previously created. Use time-travel queries in Apache Iceberg tables You can now run the following time-travel queries by using branches and tags in Apache Iceberg table snapshots: -Â SELECT \*FROM FOR VERSION AS OF 'historical-tag' -Â SELECT \*FROM

FOR VERSION AS OF 'test-branch' Access Cloud Object Storage without credentials You can now access your Cloud Object Storage bucket without credentials, by using the Content Aware Storage (CAS) endpoint. For more information about getting CAS endpoint, see Getting CAS endpoint. 28 Feb 2024 - Version 1.1.2 A new version of watsonx.data was released in February 2024. This release includes the following features and updates: SSL connection for data sources You can now enable SSL connection for the following data sources by using the Add database user interface to secure and encrypt the database connection. : Db2 PostgreSQL For more information, see Adding a database. Secure ingestion job history Now, users can view only their own ingestion job history. Administrators can view the ingestion job history for all users. SQL enhancements You can now use the following SQL statements in the Query workspace to build and run queries against your data: Apache Iceberg data sources CREATE VIEW DROP VIEW MongoDB data sources DELETE New data types BLOB and CLOB for Teradata data source New data types BLOB and CLOB are available for Teradata data source. You can use these data types only with SELECT statements in the Query workspace to build and run queries against your data. Create a new table during data ingestion Previously, you had to have a target table in watsonx.data for ingesting data. Now, you can create a new table directly from the source data file (available in parquet or CSV format) by using data ingestion from the Data Manager. You can create the table by using the following methods of ingestion: Ingesting data by using Iceberg copy loader. Ingesting data by using Spark. Perform ALTER TABLE operations on a column With an Iceberg data source, you can now

performÂ ALTER TABLEÂ operations on a column for the following data type conversions: int to bigint float to double decimal (num1,

dec\_digits) to decimal (num2, dec\_digits), where num2>num1. Better query performance by using sorted files With an Apache Iceberg data source, you can generate sorted files, which reduce the query result latency and improve the performance of Presto. Data in the Iceberg table is sorted during the writing process within each file. You can configure the order to sort the data by using the sorted\_by table property.Â When you create the table, specify an array of one or more columns involved in sorting. To disable the feature, set the session property sorted\_writing\_enabled to false. 31 Jan 2024 - Version 1.1.1 A new version of watsonx.data was released in January 2024. This release includes the following features and updates: IBM Data Virtualization Manager for z/OSÂ® connector You can now use the new IBM Data Virtualization Manager for z/OSÂ® connector to read and write IBM ZÂ® without moving, replicating, or transforming the data. For more information, see Connecting to an IBM Data Virtualization Manager (DVM) data source. Teradata connector is enabled for multiple ALTER TABLE statements Teradata connector now supports the ALTER TABLE RENAME TO, ALTER TABLE DROP COLUMN, and ALTER TABLE RENAME COLUMN column\_name TO new\_column\_name statements. Support for time travel queries Iceberg connector for Presto now supports time travel queries. The property format\_version now shows the current version The property format\_version now shows the correct value (current version) when you create an Iceberg table. 29 Nov 2023 - Version 1.1.0 A new version of watsonx.data was released in November 2023. This release includes the following features and updates: Presto case-sensitive behavior The Presto behavior is changed from case-insensitive to case- sensitive. Now you can provide the object names in the original case format as in the database. For more information, see Case-sensitive search configuration with Presto. Roll-back feature You can use the Rollback feature to rollback or rollforward to any snapshots for Iceberg tables. Capture Data Definition Language (DDL) changes You can now capture and track the DDL changes in watsonx.data by using an event listener. For more information, see Capturing DDL changes. Ingest data by using Spark You can now use the IBM Analytics Engine that is powered by Apache Spark to run ingestion jobs in watsonx.data. For more information, see Ingesting data by using Spark. Integration with Db2 and Netezza Performance Server You can now register Db2 or Netezza Performance Server engines in watsonx.data console. For more information, see Registering an engine. New connectors You can now use connectors in watsonx.data to establish connections to the following types of databases: Teradata Delta Lake Elasticsearch SingleStoreDB Snowflake For more information, see Adding a database. AWS EMR for Spark You can now run Spark applications from Amazon Web Services Elastic MapReduce (AWS EMR) to achieve the watsonx.data Spark use cases: Data ingestion Data querying Table maintenance For more information, see Using AWS EMR for Spark use case. 7 July 2023 - Version 1.0.0 watsonx.data is a new open architecture that combines the elements of the data warehouse and data lake models. The best-in-class features and optimizations available on the watsonx.data make it an optimal choice for next generation data analytics and automation. In the first release (watsonx.data 1.0.0), the following features are supported: Creating, scaling, pausing, resuming, and deleting the Presto query engine Associating and dissociating a catalog with an engine Exploring catalog objects Adding and deleting a database-catalog pair Updating database credentials Adding and deleting bucket-catalog pair Exploring bucket objects Loading data Exploring data Querying data Query history Release notes for watsonx.data Use these release notes to learn about the latest updates to IBMÂ® watsonx.data that are grouped by date. 31 May 2024 - Version 1.1.5 Provision Spark engine in watsonx.data Lite plan You can now add a small-sized Spark engine (single node) in the watsonx.data Lite plan instance. For more information, see watsonx.data Lite plan. watsonx.data Lite plan Updates related to Spark labs Working with Jupyter Notebooks from Spark labs : You can now install the Jupyter extension from the VS Code Marketplace inside your Spark lab and work with Jupyter Notebooks. For more information, see Create Jupyter Notebooks. Working with Jupyter Notebooks from Spark labs : You can now install the Jupyter extension from the VS Code Marketplace inside your Spark lab and work with Jupyter Notebooks. For more information, see Create Jupyter Notebooks. Create Jupyter Notebooks Accessing Spark UI from Spark labs You can now access the Spark user interface (UI) from Spark labs to monitor various aspects of running a Spark application. For more information, see Accessing Spark UI from Spark labs. Accessing Spark UI from Spark labs You can now access the Spark user interface (UI) from Spark labs to monitor various aspects of running a Spark application. For more information, see Accessing Spark UI from Spark labs. Accessing Spark UI from Spark labs New region to provision for IBM Cloud instance You can now provision your IBM Cloud instance in the Sydney region. 30 Apr 2024 - Version 1.1.4 A new version of watsonx.data was released in April 2024. This release includes the following features and updates: Kerberos authentication for HDFS connections You can now enable Kerberos authentication for secure Apache Hadoop Distributed File System (HDFS) connections. For more information, see HDFS. HDFS New data sources The following new data sources are now available: Oracle Amazon Redshift Informix Prometheus For more information, see Data sources. Data sources Test SSL connections You can now test SSL connections for the MongoDB and SingleStore data sources. Uploading description files for Apache Kafka data source The Apache Kafka data source stores data as byte messages that producers and consumers must interpret. To query this data, consumers must first map it into columns. Now, you can upload topic description files that convert raw data into a table format. Each file must be a JSON file that contains a definition for a table. To upload these JSON files from the UI, go to the overview page of the Apache Kafka database that you registered and select the Add topic option. For more information, see Apache Kafka. Apache Kafka License plans for watsonx.data IBMÂ® watsonx.data now offers the following license plans. Lite plan BYOL plan Enterprise plan For more information about the different license plans, see IBMÂ® watsonx.data pricing plans. IBMÂ® watsonx.data pricing plans Presto engine version upgrade The Presto engine is now upgraded to version 0.285.1. Pause or resume Milvus You can now pause or resume Milvus service. Pausing your service can avoid incurring charges. Spark is now available as a native engine In addition to registering external Spark engines, you can now provision native Spark engine on your IBM watsonx.data instance. With native Spark engine, you can fully manage Spark Engine configuration, manage access to Spark Engines and view applications by using watsonx.data UI and REST API endpoints. For more information, see Provisioning Native Spark engine. Provisioning Native Spark engine Ingest data using native Spark Engines You can now submit ingestion jobs using native Spark Engines. For more information, see Working with Apache Hudi catalog and Working with Delta Lake catalog. Working with Apache Hudi catalog Working with Delta Lake catalog 27 Mar 2024 - Version 1.1.3 A new version of watsonx.data was released in March 2024. This release includes the following features and updates: New data type for some data sources You can now use the BINARY data type with the SELECT statement in the Query workspace to build and run queries against your data for the following data sources: Elasticsearch SQL Server MySQL New data types: BLOB and CLOB are available for MySQL, PostgreSQL, Snowflake, SQL Server, and Db2 data sources. You can use these data types only with SELECT statements in the Query workspace to build and run queries against your data. Delete data by using the DELETE FROM feature for Iceberg data sources You can now delete data from tables in Iceberg data sources by using the DELETE FROM feature. You can specify the table property delete mode for new tables by using either copy-on-write mode or merge-on- read mode (default). For more information, see SQL statements. SQL statements ALTER VIEW statement for Iceberg data source You can now use the following SQL statement in the Query workspace to build and run queries against your data for ALTER VIEW: ALTER VIEW name RENAME TO new\_name Upload SSL certificates for Netezza Performance Server data sources You can now browse and upload the SSL certificate for SSL connections in Netezza Performance Server data sources. The valid file formats for SSL certificate are .pem, .crt, and .cer. You can upload SSL certificates by using the Adding a database-catalog pair option in the Infrastructure manager. Query data from Db2 and Watson Query You can now query nicknames that are created in Db2 and virtualized tables from Watson Query instances. SSL connection for IBM Data Virtualization Manager for z/OS data source You can now enable SSL connection for the IBM Data Virtualization Manager for z/OS data source by using the Add database user interface to secure and encrypt the database connection. Select Validate certificate to validate whether the SSL certificate that is returned by the host is trusted. You can choose to provide the hostname in the SSL certificate. Use data from Apache Hudi catalog You can now connect to and use data from Apache Hudi catalog. Add Milvus as a service in watsonx.data You can now provision Milvus as a service inÂ watsonx.data with the following features: Provision different storage variants such as starter, medium, and large nodes. Provision different storage variants such as starter, medium, and large nodes. Assign Admin or User roles for Milvus users: User access policy is now available for Milvus users. Using the Access Control UI, you can assign Admin or User roles for Milvus users andÂ also grant,Â revoke, or updateÂ the privilege. Assign Admin or User roles for Milvus users: User access policy is now available for Milvus users. Using the Access Control UI, you can assign Admin or User roles for Milvus users andÂ also grant,Â revoke, or updateÂ the privilege. Configure the Object storage for Milvus to store data. You can add or configure a custom bucket and specify the username, password, region, and bucket URL. Configure the Object storage for Milvus to store data. You can add or configure a custom bucket and specify the username, password, region, and bucket URL. For more information, see Milvus. Milvus Load data in batch by using the ibm-lh ingestion tool You can now use the ibm-lh ingestion tool to run batch ingestion procedures in non-interactive mode (from outside the ibm-lh-tools container), by using the ibm-lh-client package. For more information, see ibm-lh commands and usage. ibm-lh commands and usage Creating schema by using bulk ingestion in web console You can now create a schema by using the bulk ingestion process in the web console, if the schema is not previously created. Use time- travel queries in Apache Iceberg tables You can now run the following time-travel queries by using branches and tags in Apache Iceberg table snapshots: -Â SELECT \*FROM

FOR VERSION AS OF 'historical-tag' -Â SELECT \*FROM

FOR VERSION AS OF 'test-branch' Access Cloud Object Storage without credentials You can now access your Cloud Object Storage bucket without credentials, by using the Content Aware Storage (CAS) endpoint. For more information about getting CAS endpoint, see Getting CAS endpoint. Getting CAS endpoint 28 Feb 2024 - Version 1.1.2 A new version of watsonx.data was released in February 2024. This release includes the following features and updates: SSL connection for data sources You can now enable SSL connection for the following data sources by using the Add database user interface to secure and encrypt the database connection. : Db2 Db2 PostgreSQL PostgreSQL For more information, see Adding a database. Adding a database Secure ingestion job history Now, users can view only their own ingestion job history. Administrators can view the ingestion job history for all users. SQL enhancements You can now use the following SQL statements in the Query workspace to build and run queries against your data: Apache Iceberg data sources CREATE VIEW DROP VIEW CREATE VIEW DROP VIEW MongoDB data sources DELETE DELETE New data types BLOB and CLOB for Teradata data source New data types BLOB and CLOB are available for Teradata data source. You can use these data types only with SELECT statements in the Query workspace to build and run queries against your data. Create a new table during data ingestion Previously, you had to have a target table in watsonx.data for ingesting data. Now, you can create a new table directly from the source data file (available in parquet or CSV format) by using data ingestion from the Data Manager. You can create the table by using the following methods of ingestion: Ingesting data by using Iceberg copy loader. Ingesting data by using Iceberg copy loader. Ingesting data by using Spark. Ingesting data by using Spark. Perform ALTER TABLE operations on a column With an Iceberg data source, you can now performÂ ALTER TABLEÂ operations on a column for the following data type conversions: int to bigint int to bigint float to double float to double decimal (num1, dec\_digits) to decimal (num2, dec\_digits), where num2>num1. decimal (num1, dec\_digits) to decimal (num2, dec\_digits), where num2>num1. Better query performance by using sorted files With an Apache Iceberg data source, you can generate sorted files, which reduce the query result latency and improve the performance of Presto. Data in the Iceberg table is sorted during the writing process within each file. You can configure the order to sort the data by using the sorted\_by table property.Â When you create the table, specify an array of one or more columns involved in sorting. To disable the feature, set the session property sorted\_writing\_enabled to false. 31 Jan 2024 - Version 1.1.1 A new version of watsonx.data was released in January 2024. This release includes the following features and updates: IBM Data Virtualization Manager for z/OSÂ® connector You can now use the new IBM Data Virtualization Manager for z/OSÂ® connector to read and write IBM ZÂ® without moving, replicating, or transforming the data. For more information, see Connecting to an IBM Data Virtualization Manager (DVM) data source. Connecting to an IBM Data Virtualization Manager (DVM) data source Teradata connector is enabled for multiple ALTER TABLE statements Teradata connector now supports the ALTER TABLE RENAME TO, ALTER TABLE DROP COLUMN, and ALTER TABLE RENAME COLUMN column\_name TO new\_column\_name statements. Support for time travel queries Iceberg connector for Presto now supports time travel queries. The property format\_version now shows the current version The property format\_version now shows the correct value (current version) when you create an Iceberg table. 29 Nov 2023 - Version 1.1.0 A new version of watsonx.data was released in November 2023. This release includes the following features and updates: Presto case-sensitive behavior The Presto behavior is changed from case-insensitive to case-sensitive. Now you can provide the object names in the original case format as in the database. For more information, see Case-sensitive search configuration with Presto. Case-sensitive search configuration with Presto Roll-back feature You can use the Rollback feature to rollback or rollforward to any snapshots for Iceberg tables. Capture Data Definition Language (DDL) changes You can now capture and track the DDL changes in watsonx.data by using an event listener. For more information, see Capturing DDL changes. Capturing DDL changes Ingest data by using Spark You can now use the IBM Analytics Engine that is powered by Apache Spark to run ingestion jobs in watsonx.data. For more information, see Ingesting data by using Spark. Ingesting data by using Spark Integration with Db2 and Netezza Performance Server You can now register Db2 or Netezza Performance Server engines in watsonx.data console. For more information, see Registering an engine. Registering an engine New connectors You can now use connectors in watsonx.data to establish connections to the following types of databases: Teradata Delta Lake Elasticsearch SingleStoreDB Snowflake For more information, see Adding a database. Adding a database AWS EMR for Spark You can now run Spark applications from Amazon Web Services Elastic MapReduce (AWS EMR) to achieve the watsonx.data Spark use cases: Data ingestion Data querying Table maintenance For more information, see Using AWS EMR for Spark use case. Using AWS EMR for Spark use case 7 July 2023 - Version 1.0.0 watsonx.data is a new open architecture that combines the elements of the data warehouse and data lake models. The best-in-class features and optimizations available on the watsonx.data make it an optimal choice for next generation data analytics and automation. In the first release (watsonx.data 1.0.0), the following features are supported: Creating, scaling, pausing, resuming, and deleting the Presto query engine Associating and dissociating a catalog with an engine Exploring catalog objects Adding and deleting a database-catalog pair Updating database credentials Adding and deleting bucket-catalog pair Exploring bucket objects Loading data Exploring data Querying data Query history
